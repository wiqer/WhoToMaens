# MaoOCR æŠ€æœ¯å€ºåŠ¡ä¸ä¼˜åŒ–è®¡åˆ’

## ğŸš¨ æŠ€æœ¯å€ºåŠ¡æ¸…å•

### 1. é«˜ä¼˜å…ˆçº§é—®é¢˜

#### 1.1 èµ„æºç›‘æ§æ¥å£ä¸ä¸€è‡´ âœ… å·²ä¿®å¤
- **é—®é¢˜**: `ResourceMonitor.get_current_resources()` è¿”å›ç±»å‹ä¸ä¸€è‡´
- **å½±å“**: æµ‹è¯•å¤±è´¥ï¼Œç³»ç»Ÿé›†æˆé—®é¢˜
- **çŠ¶æ€**: å·²ä¿®å¤
- **ä¿®å¤æ–¹æ¡ˆ**: ç»Ÿä¸€è¿”å› `ResourceInfo` å¯¹è±¡

#### 1.2 LLMé›†æˆä¸å®Œæ•´
- **é—®é¢˜**: ç­–ç•¥é€‰æ‹©å™¨ä½¿ç”¨æ¨¡æ‹ŸLLMå®ç°
- **å½±å“**: æ™ºèƒ½ç­–ç•¥é€‰æ‹©åŠŸèƒ½å—é™
- **ä¼˜å…ˆçº§**: é«˜
- **ä¿®å¤æ–¹æ¡ˆ**:
```python
# å®ç°çœŸå®LLMé›†æˆ
def _load_qwen_model(self):
    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        self.tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-VL")
        self.model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-VL")
        logger.info("Qwen2.5-VL model loaded")
    except Exception as e:
        logger.error(f"Failed to load Qwen2.5-VL model: {e}")
        raise
```

#### 1.3 æ¨¡å‹æ–‡ä»¶ç¼ºå¤±
- **é—®é¢˜**: é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
- **å½±å“**: å®é™…OCRåŠŸèƒ½æ— æ³•æ­£å¸¸å·¥ä½œ
- **ä¼˜å…ˆçº§**: é«˜
- **ä¿®å¤æ–¹æ¡ˆ**:
  - æä¾›æ¨¡å‹ä¸‹è½½è„šæœ¬
  - ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æˆ–å¼€æºæ¨¡å‹
  - æ·»åŠ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥æœºåˆ¶

#### 1.4 é”™è¯¯å¤„ç†ä¸å®Œå–„
- **é—®é¢˜**: éƒ¨åˆ†æ¨¡å—ç¼ºå°‘å®Œæ•´çš„é”™è¯¯å¤„ç†
- **å½±å“**: ç³»ç»Ÿç¨³å®šæ€§å—å½±å“
- **ä¼˜å…ˆçº§**: é«˜
- **ä¿®å¤æ–¹æ¡ˆ**:
```python
def recognize(self, image, strategy='auto'):
    try:
        # éªŒè¯è¾“å…¥
        if not self._validate_input(image):
            raise ValueError("Invalid input image")
        
        # æ£€æŸ¥èµ„æº
        if not self._check_resources():
            raise RuntimeError("Insufficient resources")
        
        # æ‰§è¡Œè¯†åˆ«
        return self._perform_recognition(image, strategy)
        
    except Exception as e:
        logger.error(f"Recognition failed: {e}")
        return self._create_error_result(str(e))
```

#### 1.5 PP-OCRv5 + OpenVINO é›†æˆä¸å®Œæ•´
- **é—®é¢˜**: OpenVINOå¼•æ“ç¼ºå°‘å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ç›‘æ§
- **å½±å“**: ç”Ÿäº§ç¯å¢ƒç¨³å®šæ€§ä¸è¶³ï¼Œæ€§èƒ½ä¼˜åŒ–ç¼ºä¹æ•°æ®æ”¯æŒ
- **ä¼˜å…ˆçº§**: é«˜
- **ä¿®å¤æ–¹æ¡ˆ**:
```python
class OpenVINOEngine:
    def __init__(self, config):
        self.config = config
        self.performance_monitor = PerformanceMonitor()
        self.error_handler = ErrorHandler()
        
    async def inference(self, images):
        try:
            # æ€§èƒ½ç›‘æ§
            start_time = time.time()
            
            # è®¾å¤‡çŠ¶æ€æ£€æŸ¥
            if not self._check_device_status():
                raise RuntimeError("OpenVINO device not available")
            
            # æ‰§è¡Œæ¨ç†
            results = await self._perform_inference(images)
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            inference_time = time.time() - start_time
            self.performance_monitor.record_inference(
                batch_size=len(images),
                inference_time=inference_time,
                device=self.config.device
            )
            
            return results
            
        except Exception as e:
            self.error_handler.handle_error(e, context="OpenVINO inference")
            raise
```

### 2. ä¸­ä¼˜å…ˆçº§é—®é¢˜

#### 2.1 æµ‹è¯•è¦†ç›–ç‡ä¸è¶³
- **é—®é¢˜**: å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•ä¸å®Œæ•´
- **å½±å“**: ä»£ç è´¨é‡ä¿è¯ä¸è¶³
- **ä¼˜å…ˆçº§**: ä¸­
- **ä¿®å¤æ–¹æ¡ˆ**:
  - æ·»åŠ å•å…ƒæµ‹è¯•
  - å®Œå–„é›†æˆæµ‹è¯•
  - æ·»åŠ æ€§èƒ½åŸºå‡†æµ‹è¯•

#### 2.2 æ€§èƒ½ç›‘æ§ä¸å®Œæ•´
- **é—®é¢˜**: æ€§èƒ½æŒ‡æ ‡æ”¶é›†ä¸å…¨é¢
- **å½±å“**: æ€§èƒ½ä¼˜åŒ–ç¼ºä¹æ•°æ®æ”¯æŒ
- **ä¼˜å…ˆçº§**: ä¸­
- **ä¿®å¤æ–¹æ¡ˆ**:
```python
@dataclass
class PerformanceMetrics:
    accuracy: float
    speed: float  # pages/minute
    memory_usage: float  # GB
    gpu_utilization: float
    latency: float  # ms
    throughput: float  # images/second
    error_rate: float
```

#### 2.3 é…ç½®ç®¡ç†ä¸çµæ´»
- **é—®é¢˜**: é…ç½®æ–‡ä»¶ç¡¬ç¼–ç ï¼Œç¼ºä¹ç¯å¢ƒå˜é‡æ”¯æŒ
- **å½±å“**: éƒ¨ç½²çµæ´»æ€§ä¸è¶³
- **ä¼˜å…ˆçº§**: ä¸­
- **ä¿®å¤æ–¹æ¡ˆ**:
```yaml
# æ”¯æŒç¯å¢ƒå˜é‡
llm:
  type: ${LLM_TYPE:-"qwen2.5-vl"}
  model_path: ${LLM_MODEL_PATH:-"models/qwen2.5-vl"}

detectors:
  fast:
    model_path: ${FAST_DETECTOR_PATH:-"models/detectors/fast_detector.onnx"}
```

### 3. ä½ä¼˜å…ˆçº§é—®é¢˜

#### 3.1 æ—¥å¿—ç³»ç»Ÿä¸å®Œå–„
- **é—®é¢˜**: æ—¥å¿—æ ¼å¼ä¸ç»Ÿä¸€ï¼Œç¼ºä¹ç»“æ„åŒ–æ—¥å¿—
- **å½±å“**: é—®é¢˜æ’æŸ¥å›°éš¾
- **ä¼˜å…ˆçº§**: ä½
- **ä¿®å¤æ–¹æ¡ˆ**:
```python
import structlog

logger = structlog.get_logger()

def recognize(self, image, strategy='auto'):
    logger.info("Starting OCR recognition",
                strategy=strategy,
                image_size=image.size if hasattr(image, 'size') else 'unknown')
```

#### 3.2 æ–‡æ¡£ä¸å®Œæ•´
- **é—®é¢˜**: APIæ–‡æ¡£å’Œç”¨æˆ·æŒ‡å—ä¸å®Œæ•´
- **å½±å“**: ç”¨æˆ·ä½“éªŒä¸ä½³
- **ä¼˜å…ˆçº§**: ä½
- **ä¿®å¤æ–¹æ¡ˆ**:
  - ç”ŸæˆAPIæ–‡æ¡£
  - å®Œå–„ç”¨æˆ·æŒ‡å—
  - æ·»åŠ ä»£ç ç¤ºä¾‹

## ğŸ¯ ä¼˜åŒ–è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¿®å¤ï¼ˆ1-2å‘¨ï¼‰

#### 1.1 ä¿®å¤æ ¸å¿ƒé—®é¢˜
- [x] ä¿®å¤èµ„æºç›‘æ§æ¥å£ä¸ä¸€è‡´
- [ ] å®ç°çœŸå®LLMé›†æˆ
- [ ] æ·»åŠ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥æœºåˆ¶
- [ ] å®Œå–„é”™è¯¯å¤„ç†

#### 1.2 åŸºç¡€æµ‹è¯•
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•
- [ ] å®Œå–„é›†æˆæµ‹è¯•
- [ ] æ·»åŠ æ€§èƒ½åŸºå‡†æµ‹è¯•

### ç¬¬äºŒé˜¶æ®µï¼šåŠŸèƒ½å¢å¼ºï¼ˆ2-3å‘¨ï¼‰

#### 2.1 æ€§èƒ½ä¼˜åŒ–
- [ ] å®ç°æ¨¡å‹ç¼“å­˜æœºåˆ¶
- [ ] æ·»åŠ å¼‚æ­¥å¤„ç†æ”¯æŒ
- [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨

#### 2.2 ç›‘æ§å®Œå–„
- [ ] å®Œå–„æ€§èƒ½ç›‘æ§
- [ ] æ·»åŠ å¥åº·æ£€æŸ¥
- [ ] å®ç°å‘Šè­¦æœºåˆ¶

#### 2.3 PP-OCRv5 + OpenVINO ä¼˜åŒ–
- [ ] å®Œå–„OpenVINOå¼•æ“é”™è¯¯å¤„ç†
- [ ] å®ç°åŠ¨æ€æƒé‡è°ƒæ•´æœºåˆ¶
- [ ] æ·»åŠ å¼•æ“æ€§èƒ½å¯¹æ¯”åŠŸèƒ½
- [ ] ä¼˜åŒ–è®¾å¤‡ç®¡ç†å’Œåˆ‡æ¢
- [ ] å®ç°è‡ªé€‚åº”æ‰¹å¤„ç†å¤§å°

### ç¬¬ä¸‰é˜¶æ®µï¼šç”¨æˆ·ä½“éªŒï¼ˆ1-2å‘¨ï¼‰

#### 3.1 æ–‡æ¡£å®Œå–„
- [ ] ç”ŸæˆAPIæ–‡æ¡£
- [ ] å®Œå–„ç”¨æˆ·æŒ‡å—
- [ ] æ·»åŠ ä»£ç ç¤ºä¾‹

#### 3.2 éƒ¨ç½²ä¼˜åŒ–
- [ ] æ·»åŠ Dockeræ”¯æŒ
- [ ] å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²
- [ ] æ·»åŠ é…ç½®éªŒè¯

## ğŸ”§ å…·ä½“å®ç°æ–¹æ¡ˆ

### 1. LLMé›†æˆå®ç°

#### 1.1 ä¾èµ–ç®¡ç†
```python
# requirements.txt æ·»åŠ 
transformers>=4.30.0
torch>=2.0.0
accelerate>=0.20.0
```

#### 1.2 æ¨¡å‹åŠ è½½
```python
class LLMStrategySelector:
    def _load_qwen_model(self):
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM
            from accelerate import Accelerator
            
            self.accelerator = Accelerator()
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                "Qwen/Qwen2.5-VL",
                trust_remote_code=True
            )
            self.model = AutoModelForCausalLM.from_pretrained(
                "Qwen/Qwen2.5-VL",
                trust_remote_code=True,
                device_map="auto"
            )
            
            self.model, self.tokenizer = self.accelerator.prepare(
                self.model, self.tokenizer
            )
            
            logger.info("Qwen2.5-VL model loaded successfully")
            
        except Exception as e:
            logger.error(f"Failed to load Qwen2.5-VL model: {e}")
            raise
```

#### 1.3 æ¨ç†å®ç°
```python
def _evaluate_with_llm(self, image, candidates, complexity, resources):
    try:
        # æ„å»ºæç¤ºè¯
        prompt = self._build_evaluation_prompt(candidates, complexity, resources)
        
        # ç¼–ç è¾“å…¥
        inputs = self.tokenizer(
            prompt,
            return_tensors="pt",
            max_length=512,
            truncation=True
        )
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=256,
                temperature=0.1,
                do_sample=True
            )
        
        # è§£ç è¾“å‡º
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # è§£æç»“æœ
        return self._parse_llm_response(response, candidates)
        
    except Exception as e:
        logger.error(f"LLM evaluation failed: {e}")
        # è¿”å›é»˜è®¤ç­–ç•¥
        return candidates[0]
```

### 2. æ¨¡å‹ç®¡ç†å®ç°

#### 2.1 æ¨¡å‹ä¸‹è½½è„šæœ¬
```python
#!/usr/bin/env python3
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
"""

import os
import requests
from pathlib import Path
from tqdm import tqdm

def download_model(model_url: str, save_path: Path):
    """ä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
    save_path.parent.mkdir(parents=True, exist_ok=True)
    
    response = requests.get(model_url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(save_path, 'wb') as f:
        with tqdm(total=total_size, unit='B', unit_scale=True) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                pbar.update(len(chunk))

def main():
    """ä¸»å‡½æ•°"""
    models = {
        "fast_detector.onnx": "https://example.com/models/fast_detector.onnx",
        "precise_detector.pth": "https://example.com/models/precise_detector.pth",
        "light_recognizer.onnx": "https://example.com/models/light_recognizer.onnx",
        "chinese_recognizer.pth": "https://example.com/models/chinese_recognizer.pth"
    }
    
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    for model_name, model_url in models.items():
        model_path = models_dir / model_name
        if not model_path.exists():
            print(f"Downloading {model_name}...")
            download_model(model_url, model_path)
        else:
            print(f"{model_name} already exists")

if __name__ == "__main__":
    main()
```

#### 2.2 æ¨¡å‹æ–‡ä»¶æ£€æŸ¥
```python
class ModelFileChecker:
    """æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å™¨"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
    
    def check_all_models(self) -> Dict[str, bool]:
        """æ£€æŸ¥æ‰€æœ‰æ¨¡å‹æ–‡ä»¶"""
        results = {}
        
        # æ£€æŸ¥æ£€æµ‹å™¨æ¨¡å‹
        for detector_name, config in self.config.get('detectors', {}).items():
            model_path = Path(config.get('model_path', ''))
            results[f"detector_{detector_name}"] = model_path.exists()
        
        # æ£€æŸ¥è¯†åˆ«å™¨æ¨¡å‹
        for recognizer_name, config in self.config.get('recognizers', {}).items():
            model_path = Path(config.get('model_path', ''))
            results[f"recognizer_{recognizer_name}"] = model_path.exists()
        
        return results
    
    def get_missing_models(self) -> List[str]:
        """è·å–ç¼ºå¤±çš„æ¨¡å‹æ–‡ä»¶"""
        model_status = self.check_all_models()
        return [model for model, exists in model_status.items() if not exists]
```

### 3. é”™è¯¯å¤„ç†å®Œå–„

#### 3.1 è‡ªå®šä¹‰å¼‚å¸¸ç±»
```python
class MaoOCRError(Exception):
    """MaoOCRåŸºç¡€å¼‚å¸¸ç±»"""
    pass

class ValidationError(MaoOCRError):
    """è¾“å…¥éªŒè¯é”™è¯¯"""
    pass

class ResourceError(MaoOCRError):
    """èµ„æºä¸è¶³é”™è¯¯"""
    pass

class ModelError(MaoOCRError):
    """æ¨¡å‹ç›¸å…³é”™è¯¯"""
    pass

class StrategyError(MaoOCRError):
    """ç­–ç•¥é€‰æ‹©é”™è¯¯"""
    pass
```

#### 3.2 é”™è¯¯å¤„ç†è£…é¥°å™¨
```python
def handle_ocr_errors(func):
    """OCRé”™è¯¯å¤„ç†è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except ValidationError as e:
            logger.warning(f"Validation error: {e}")
            return create_error_result("Invalid input", str(e))
        except ResourceError as e:
            logger.warning(f"Resource error: {e}")
            return create_error_result("Insufficient resources", str(e))
        except ModelError as e:
            logger.error(f"Model error: {e}")
            return create_error_result("Model error", str(e))
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            return create_error_result("Internal error", str(e))
    return wrapper
```

### 4. æµ‹è¯•å®Œå–„

#### 4.1 å•å…ƒæµ‹è¯•
```python
# tests/test_maoocr.py
import pytest
from unittest.mock import Mock, patch
from src.maoocr import MaoOCR

class TestMaoOCR:
    def setup_method(self):
        self.ocr = MaoOCR("configs/maoocr_config.yaml")
    
    def test_recognize_with_valid_image(self):
        """æµ‹è¯•æœ‰æ•ˆå›¾åƒè¯†åˆ«"""
        # åˆ›å»ºæ¨¡æ‹Ÿå›¾åƒ
        mock_image = Mock()
        mock_image.size = (800, 600)
        
        # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
        with patch.object(self.ocr, '_perform_recognition') as mock_recognition:
            mock_recognition.return_value = create_mock_result()
            
            result = self.ocr.recognize(mock_image)
            
            assert result.text is not None
            assert result.confidence >= 0.0
            assert result.confidence <= 1.0
    
    def test_recognize_with_invalid_image(self):
        """æµ‹è¯•æ— æ•ˆå›¾åƒè¯†åˆ«"""
        with pytest.raises(ValidationError):
            self.ocr.recognize(None)
    
    def test_strategy_selection(self):
        """æµ‹è¯•ç­–ç•¥é€‰æ‹©"""
        # æµ‹è¯•è‡ªåŠ¨ç­–ç•¥
        result = self.ocr.recognize(mock_image, strategy='auto')
        assert result.strategy_used == StrategyType.AUTO
        
        # æµ‹è¯•æ‰‹åŠ¨ç­–ç•¥
        result = self.ocr.recognize(mock_image, strategy='fast:chinese')
        assert result.strategy_used == StrategyType.MANUAL
```

#### 4.2 é›†æˆæµ‹è¯•
```python
# tests/test_integration.py
import pytest
from pathlib import Path

class TestIntegration:
    def test_full_ocr_pipeline(self):
        """æµ‹è¯•å®Œæ•´OCRæµæ°´çº¿"""
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image = create_test_image()
        
        # æ‰§è¡ŒOCR
        ocr = MaoOCR("configs/maoocr_config.yaml")
        result = ocr.recognize(test_image)
        
        # éªŒè¯ç»“æœ
        assert result.text is not None
        assert len(result.text) > 0
        assert result.confidence > 0.5
        assert result.total_time > 0
    
    def test_performance_benchmark(self):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        ocr = MaoOCR("configs/maoocr_config.yaml")
        
        # æµ‹è¯•ä¸åŒç­–ç•¥çš„æ€§èƒ½
        strategies = ['fast:light', 'precise:chinese', 'smart:multimodal']
        results = {}
        
        for strategy in strategies:
            start_time = time.time()
            result = ocr.recognize(test_image, strategy=strategy)
            end_time = time.time()
            
            results[strategy] = {
                'time': end_time - start_time,
                'confidence': result.confidence
            }
        
        # éªŒè¯æ€§èƒ½è¦æ±‚
        assert results['fast:light']['time'] < 2.0  # å¿«é€Ÿç­–ç•¥åº”åœ¨2ç§’å†…
        assert results['precise:chinese']['confidence'] > 0.8  # ç²¾ç¡®ç­–ç•¥åº”æœ‰é«˜ç½®ä¿¡åº¦
```

## ğŸ“Š è¿›åº¦è·Ÿè¸ª

### å½“å‰è¿›åº¦
- [x] é¡¹ç›®æ¶æ„è®¾è®¡
- [x] æ ¸å¿ƒåŠŸèƒ½å®ç°
- [x] é€‚é…å™¨æ¨¡å¼å®ç°
- [x] è£…é¥°å™¨æ¨¡å¼å®ç°
- [x] ç­–ç•¥é€‰æ‹©å™¨æ¡†æ¶
- [x] èµ„æºç›‘æ§åŸºç¡€å®ç°
- [x] é…ç½®æ–‡ä»¶ç®¡ç†
- [x] åŸºç¡€æµ‹è¯•æ¡†æ¶

### å¾…å®Œæˆé¡¹ç›®
- [ ] LLMçœŸå®é›†æˆ
- [ ] æ¨¡å‹æ–‡ä»¶ç®¡ç†
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æµ‹è¯•è¦†ç›–ç‡æå‡
- [ ] æ€§èƒ½ç›‘æ§å®Œå–„
- [ ] æ–‡æ¡£å®Œå–„
- [ ] éƒ¨ç½²ä¼˜åŒ–

## ğŸ¯ æˆåŠŸæ ‡å‡†

### åŠŸèƒ½å®Œæ•´æ€§
- [ ] æ‰€æœ‰OCRå¼•æ“æ­£å¸¸å·¥ä½œ
- [ ] æ™ºèƒ½ç­–ç•¥é€‰æ‹©åŠŸèƒ½å®Œæ•´
- [ ] èµ„æºç®¡ç†åŠŸèƒ½å®Œå–„
- [ ] é”™è¯¯å¤„ç†æœºåˆ¶å¥å…¨

### æ€§èƒ½æŒ‡æ ‡
- [ ] å¿«é€Ÿç­–ç•¥ï¼š< 2ç§’å¤„ç†æ—¶é—´
- [ ] ç²¾ç¡®ç­–ç•¥ï¼š> 90%å‡†ç¡®ç‡
- [ ] å†…å­˜ä½¿ç”¨ï¼š< 8GB
- [ ] GPUåˆ©ç”¨ç‡ï¼š> 80%

### ä»£ç è´¨é‡
- [ ] æµ‹è¯•è¦†ç›–ç‡ï¼š> 80%
- [ ] ä»£ç å¤æ‚åº¦ï¼š< 10
- [ ] æ–‡æ¡£è¦†ç›–ç‡ï¼š100%
- [ ] é”™è¯¯ç‡ï¼š< 1%

## ğŸ“ æ€»ç»“

MaoOCRé¡¹ç›®åœ¨æ¶æ„è®¾è®¡å’Œæ ¸å¿ƒåŠŸèƒ½å®ç°æ–¹é¢å·²ç»å–å¾—äº†è‰¯å¥½çš„è¿›å±•ï¼Œä½†åœ¨ç»†èŠ‚å®ç°å’Œç³»ç»Ÿé›†æˆæ–¹é¢è¿˜éœ€è¦è¿›ä¸€æ­¥å®Œå–„ã€‚é€šè¿‡ç³»ç»Ÿæ€§çš„æŠ€æœ¯å€ºåŠ¡æ¸…ç†å’Œä¼˜åŒ–è®¡åˆ’æ‰§è¡Œï¼Œé¡¹ç›®å°†èƒ½å¤Ÿè¾¾åˆ°é¢„æœŸçš„åŠŸèƒ½å®Œæ•´æ€§å’Œæ€§èƒ½æŒ‡æ ‡ã€‚

**å…³é”®æˆåŠŸå› ç´ **:
1. ä¼˜å…ˆä¿®å¤é«˜ä¼˜å…ˆçº§é—®é¢˜
2. å®Œå–„æµ‹è¯•å’Œç›‘æ§
3. æå‡ç”¨æˆ·ä½“éªŒ
4. å»ºç«‹æŒç»­æ”¹è¿›æœºåˆ¶